{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://livebook.manning.com/#!/book/deep-learning-with-pytorch/chapter-4/v-4/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1  Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-01 21:55:36--  http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 264426 (258K) [text/csv]\n",
      "Saving to: ‘winequality-white.csv’\n",
      "\n",
      "winequality-white.c 100%[===================>] 258.23K   370KB/s    in 0.7s    \n",
      "\n",
      "2018-11-01 21:55:37 (370 KB/s) - ‘winequality-white.csv’ saved [264426/264426]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineq_numpy = np.loadtxt(\"winequality-white.csv\", dtype=np.float32, delimiter=\";\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wineq[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.,  6.,  6.,  ...,  6.,  7.,  6.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  6,  6,  ...,  6,  7,  6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]),\n",
       " torch.Size([1, 4898]),\n",
       " torch.Size([4898, 1]),\n",
       " torch.Size([4898, 10]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape, target.unsqueeze(0).shape, target.unsqueeze(1).shape, target_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot.scatter_(dim=1, index=target.unsqueeze(1), value=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   6.8548,    0.2782,    0.3342,    6.3914,    0.0458,   35.3081,\n",
       "         138.3607,    0.9940,    3.1883,    0.4898,   10.5142])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.1211e-01,  1.0160e-02,  1.4646e-02,  2.5726e+01,  4.7733e-04,\n",
       "         2.8924e+02,  1.8061e+03,  8.9455e-06,  2.2801e-02,  1.3025e-02,\n",
       "         1.5144e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.1721,  -0.0818,   0.2133,  ...,  -1.2468,  -0.3491,\n",
       "          -1.3930],\n",
       "        [ -0.6574,   0.2159,   0.0480,  ...,   0.7399,   0.0013,\n",
       "          -0.8242],\n",
       "        [  1.4756,   0.0174,   0.5438,  ...,   0.4750,  -0.4368,\n",
       "          -0.3366],\n",
       "        ...,\n",
       "        [ -0.4204,  -0.3794,  -1.1915,  ...,  -1.3131,  -0.2615,\n",
       "          -0.9054],\n",
       "        [ -1.6054,   0.1167,  -0.2825,  ...,   1.0048,  -0.9625,\n",
       "           1.8574],\n",
       "        [ -1.0129,  -0.6770,   0.3785,  ...,   0.4750,  -1.4882,\n",
       "           1.0448]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = (data-data_mean) / torch.sqrt(data_var)\n",
    "data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad = data[torch.le(target, 3).long()]\n",
    "data_good = data[torch.ge(target, 7).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   6.9971,    0.2701,    0.3599,   20.6227,    0.0450,   44.8734,\n",
       "         169.8448,    1.0010,    3.0012,    0.4501,    8.8033])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(data_bad, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   6.8486,    0.2765,    0.3557,   16.5668,    0.0459,   38.2911,\n",
       "         161.7762,    0.9995,    3.0649,    0.4586,    8.9518])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(data_good, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  ...,  0,  0,  0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.le(target, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2  Time Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-01 22:33:04--  https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 279992 (273K) [application/zip]\n",
      "Saving to: ‘Bike-Sharing-Dataset.zip’\n",
      "\n",
      "Bike-Sharing-Datase 100%[===================>] 273.43K   389KB/s    in 0.7s    \n",
      "\n",
      "2018-11-01 22:33:05 (389 KB/s) - ‘Bike-Sharing-Dataset.zip’ saved [279992/279992]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Bike-Sharing-Dataset.zip\r\n",
      "  inflating: Readme.txt              \r\n",
      "  inflating: day.csv                 \r\n",
      "  inflating: hour.csv                \r\n"
     ]
    }
   ],
   "source": [
    "!unzip Bike-Sharing-Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('hour.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-01    24\n",
       "2011-01-02    23\n",
       "2011-01-03    22\n",
       "2011-01-04    23\n",
       "2011-01-05    23\n",
       "2011-01-06    23\n",
       "2011-01-07    23\n",
       "2011-01-08    24\n",
       "2011-01-09    24\n",
       "2011-01-10    24\n",
       "2011-01-11    22\n",
       "2011-01-12    22\n",
       "2011-01-13    24\n",
       "2011-01-14    23\n",
       "2011-01-15    24\n",
       "2011-01-16    24\n",
       "2011-01-17    24\n",
       "2011-01-18    12\n",
       "2011-01-19    23\n",
       "2011-01-20    24\n",
       "2011-01-21    24\n",
       "2011-01-22    23\n",
       "2011-01-23    23\n",
       "2011-01-24    23\n",
       "2011-01-25    23\n",
       "2011-01-26    16\n",
       "2011-01-27     8\n",
       "2011-01-28    23\n",
       "2011-01-29    23\n",
       "2011-01-30    23\n",
       "              ..\n",
       "2012-12-02    24\n",
       "2012-12-03    24\n",
       "2012-12-04    24\n",
       "2012-12-05    24\n",
       "2012-12-06    24\n",
       "2012-12-07    24\n",
       "2012-12-08    24\n",
       "2012-12-09    24\n",
       "2012-12-10    24\n",
       "2012-12-11    24\n",
       "2012-12-12    24\n",
       "2012-12-13    24\n",
       "2012-12-14    24\n",
       "2012-12-15    24\n",
       "2012-12-16    24\n",
       "2012-12-17    24\n",
       "2012-12-18    24\n",
       "2012-12-19    24\n",
       "2012-12-20    24\n",
       "2012-12-21    24\n",
       "2012-12-22    24\n",
       "2012-12-23    24\n",
       "2012-12-24    23\n",
       "2012-12-25    23\n",
       "2012-12-26    24\n",
       "2012-12-27    24\n",
       "2012-12-28    24\n",
       "2012-12-29    24\n",
       "2012-12-30    24\n",
       "2012-12-31    24\n",
       "Name: dteday, Length: 731, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dteday.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_numpy = np.loadtxt(\"hour.csv\", dtype=np.float32, delimiter=\",\", skiprows=1, \n",
    "                         converters={1: lambda x: float(x[8:10])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., 31., 31., 31.], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17379, 17)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = torch.from_numpy(bikes_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     1.,      2.,      3.,  ...,  17377.,  17378.,  17379.]),\n",
       " tensor([     0,      1,      2,  ...,  17376,  17377,  17378]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(bikes[:, 0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sorted_row_idxs = torch.sort(bikes[:, 0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,      1,      2,  ...,  17376,  17377,  17378])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_row_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = bikes[sorted_row_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = bikes[:17376].view(-1, 24, bikes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 24, 17])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 17, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 17, 24])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 1, 17)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 24])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot = torch.zeros(bikes.shape[0], 4)\n",
    "weather_onehot.scatter_(1, bikes[:, 9].long().unsqueeze(1)-1, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = torch.cat((bikes, weather_onehot), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17379, 21])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 4, 24])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.scatter_(1, daily_bikes[:, 9, :].long().unsqueeze(1)-1, 1.)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 17, 24])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 21, 24])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 24])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes[:, 9, :].long().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([724, 1, 24])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes[:, 9, :].long().unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3  Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-02 09:05:24--  http://www.gutenberg.org/files/1342/1342-0.txt\n",
      "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47\n",
      "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 724725 (708K) [text/plain]\n",
      "Saving to: ‘1342-0.txt’\n",
      "\n",
      "1342-0.txt          100%[===================>] 707.74K  2.00MB/s    in 0.3s    \n",
      "\n",
      "2018-11-02 09:05:25 (2.00 MB/s) - ‘1342-0.txt’ saved [724725/724725]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.gutenberg.org/files/1342/1342-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('1342-0.txt') as f: text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, 704190)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text), len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) \n",
    "                   if unicodedata.category(c) != 'Mn' and c in all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = lines[200]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 56])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor = torch.zeros(len(line), n_letters)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = all_letters.find(letter)\n",
    "    tensor[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so incidentally, this is the shape recurrent neural networks expect the input to be: (sentence_length, n_sentences, n_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 1, 56])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.unsqueeze(tensor, 1)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124592"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = text.lower().replace('\\n', ' ').split()\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(set, 7261)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = '.,;:\"!?”“_-'\n",
    "all_words = {word.strip(punctuation) for word in all_words}\n",
    "type(all_words), len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict, 7261)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = {w:i for i,w in enumerate(all_words)}\n",
    "\n",
    "type(all_words), len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impossible',\n",
       " 'mr',\n",
       " 'bennet',\n",
       " 'impossible',\n",
       " 'when',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'acquainted',\n",
       " 'with',\n",
       " 'him']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_line = [word.strip(punctuation) for word in line.lower().split(' ')]\n",
    "words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 7261])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros(len(words_in_line), len(all_words))\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(words_in_line):\n",
    "    tensor[i][all_words[word]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use unsqueeze to make room for an extra dimension, to obtain a (sequence_length, n_sentences, n_words) shaped tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 7261])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.unsqueeze(1)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4  Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, waveform_arr = wavfile.read('1-100038-A-14.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -388, -3387, -4634, ...,  2289,  1327,    90], dtype=int16)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220500,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torch.from_numpy(waveform_arr).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the kind of network employed for carrying out a task, for instance a sound classification task, we would be required to lay out the tensor in one of two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For architectures based on filtering the 1D signal with cascades of learned filter banks, such as convolutional networks, we would need to lay out the tensor as B x C x L, where B is the batch (the number of sounds in a dataset), C the number of channels and L the number of samples in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, for architectures that incorporate the notion of temporal sequences, just as recurrent networks we mentioned for text, data needs to be laied out as L x B x C - sequence length comes first. Intuitively, this is because the latter architectures take one set of C values at a time - the signal is not considered as a whole, but as an individual input changing in time.\n",
    "\n",
    "This is the same as above (text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_arr, t_arr, sp_arr = signal.spectrogram(waveform_arr, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(129,), (984,), (129, 984)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[o.shape for o in (f_arr, t_arr, sp_arr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = torch.from_numpy(sp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11fcb1b70>]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VHXe/vH3J51AqAmdSAvSUYiAYsEO2FDXXcsqa0Ndy67rs4qre+m67q76rProPtZV1t6xsHbsBRWCYugQihBpgUCoISTz+f2Rwz75mdDSzkxyv65rrsx858zMnZNy53zPmRNzd0RERCqKCzuAiIhEH5WDiIhUonIQEZFKVA4iIlKJykFERCpROYiISCUqBxERqUTlICIilagcRESkkoSwA1RXenq6d+3aNewYIiIxZcaMGevcPWNvy8VsOXTt2pWcnJywY4iIxBQz+2FfltO0koiIVKJyEBGRSlQOIiJSicpBREQqUTmIiEglKgcREalE5SAiIpWoHEREYsTigi2UlkXq5bVUDiIiMSAScS5/egZPfbVP72GrsZh9h7SISGOQm7+RrLZpNEmK5/5zDqZtWnK9vK62HEREotD2kjL+8tZcxj7wJQ99uhiAPh2a06ZZ/ZSDthxERKLM1MXrmDBpFssLt3HesEwuPaJbvWdQOYiIRIlNxTv529vzeX7acrq2SeWF8cMZ3r1NKFlUDiIiUeCDuWu46fVZFGzewWVHdue3x/WiSVJ8aHlUDiIiIdpZFuG6l75n8vcr6d0+jX9ekM3Azi3DjqVyEBEJU2J8HAnxxu+O78XlR/UgKSE6jhOKjhQiIo3I2k3FXPZ0DovWbAbg7rMGcc2xWVFTDKByEBGpd3Fxxqz8Ihau2QKAmYWcqDKVg4hIPVi6biu3Tp5DWcRJb5bMJ78/mpMGdgg71m5pn4OISB0qLYvw+BdLuWfKQpIS4jh3WCa92qVF1RRSVVQOIiJ1ZN6qTdwwKZfc/CJO6NuOP4/tT7vmKWHH2icqBxGRWrajtIwHPsrjwU8W0zI1kQfOHcyYAe2jct/C7qgcRERq0bfLN3DDK7ksWruFMwZ34o8n9aVV06SwY+23vU56mVkXM/vYzOaZ2Rwz+00w3trMppjZouBjq2DczOx+M8szs1wzG1zhucYFyy8ys3EVxoeY2azgMfdbLNWriEhg+rJCznxoKlt3lPKvCw/hnp8fFJPFAPt2tFIpcJ279wGGA1eaWV9gAvChu2cBHwa3AUYDWcFlPPAQlJcJcAswDBgK3LKrUIJlxld43Kiaf2oiIvVj/ZYdAAzJbMUfRvfh/d8dxdEHtg05Vc3stRzcfZW7fxtc3wzMAzoBpwFPBos9CYwNrp8GPOXlvgZamlkH4ERgirsXuvsGYAowKrivubt/5e4OPFXhuUREotpjny/h2Hs+Ze3mYuLijEuP7E6z5Nifsd+vz8DMugIHA98A7dx9FZQXiJntqslOwIoKD8sPxvY0nl/FuIhI1NpRWkZyQjxH927L+q0lNE9JDDtSrdrnA23NrBkwCfitu2/a06JVjHk1xqvKMN7Mcswsp6CgYG+RRURqXcHmHVz57Ldc++JMAHpkNOOGUb1JSQzvDKp1YZ/KwcwSKS+GZ9391WB4TTAlRPBxbTCeD3Sp8PDOwMq9jHeuYrwSd3/U3bPdPTsjI2NfoouI1Ap3Z9KMfI6751OmzF1Dv44tiESq/Du2QdiXo5UMeByY5+73VLhrMrDriKNxwBsVxi8IjloaDhQF00/vASeYWatgR/QJwHvBfZvNbHjwWhdUeC4RkdD9uHE7v/rXdK57+Xt6tm3G2785giuP7klcXMM9sHJf9jmMAM4HZpnZzGDsD8AdwEtmdjGwHDgruO9tYAyQB2wDLgRw90Iz+zMwPVjuNncvDK5fATwBNAHeCS4iIqGKRJxnvvmBO9+ZjwN/OrUf5w8/oEGXwi5WfoBQ7MnOzvacnJywY4hIA7W4YAsTJuUyfdkGjshK56+nD6BL69SwY9WYmc1w9+y9LRf7x1uJiNSBSTPyWbhmC38/axBnDu4UU6e+qA0qBxGRwJyVRRTvLGPIAa255tgsfjWiK23TYuNEebUtus8ZKyJSTyIR57cvzOQvb83D3UlJjG+0xQDachCRRm7GDxvo0yGN1KQEHjhvMG3TkhvdFFJVtOUgIo3S1h2l3Dp5Dj97eCoPf7oEgF7t0miZGpsnyqtt2nIQkUbns4UF3PjqLFYWbWfcoV257MjuYUeKOioHEWk0Nm4r4fa35vHKjHy6ZzTl5csOJbtr67BjRSWVg4g0Cu/MWsUf35jDhm0lXHl0D64+JqvBnQ+pNqkcRKRBKymN8JsXvuOd2avp17E5T150CP06tgg7VtRTOYhIg5aUEEdaSgLXjzqQS4/oTmK8jsPZF1pLItLgrC4q5uInprNg9WYA7vrZIH49sqeKYT9oTYlIg5MYbyxcu5klBVvCjhKzVA4i0iDkrd3Mza/PoizitGmWzEfXjWT0gA5hx4pZKgcRiWk7yyL870eLGHPfF7yZu+o/WwuaQqoZ7ZAWkZg1+8cifv9KLvNWbeKkgR249ZR+ZKQlhx2rQVA5iEjMKd5Zxv98sIh/fr6E1k2TeOT8IZzYr33YsRoUlYOIxJRpSwuZMCmXJeu28ovsLvxhTB9apCaGHavBUTmISMyYtrSQnz/yFZ1bNeGZi4dxeFZ62JEaLJWDiES9tZuLaZuWQvYBrbjllL784pAupCbp11dd0u58EYlqj3y6mOPu/pS1m4qJizMuHNFNxVAPtIZFJOq4OztKI6QkxnNCv/ZsLSnTfoV6pnIQkaiyZlMxN78+mziDh385hG7pTfnd8b3CjtXoaFpJRKKCu/Pi9OUcd8+nfLawgIMzW+EedqrGS1sOIhK65eu3MeHVXKYuXs/Qbq2588yBdEtvGnasRk3lICKhKYs4T0xdxt/fW0B8nHH72P6cOzSTuDgLO1qjp3IQkVAsXLOZ61/JZeaKjRzTuy23j+1Px5ZNwo4lAZWDiITijZk/8sP6rdx39kGcOqgjZtpaiCYqBxGpN7n5G9lRGuGQrq25+pgsLhzRjfRmOlFeNNLRSiJSLyIR579e/p4735kPQEpivIohimnLQUTq1PRlhfTt0JymyQk8eN5gMtJSwo4k+0BbDiJSJzYX7+Sm12Zx1sNf8ehnSwDo2TaNFk30TudYoC0HEal1H81fw02vzWbNpmIuObwblx/VI+xIsp9UDiJSawq3lnDbv+fw+syV9GrXjAfPO4yDM1uFHUuqQeUgIjXm7vw7dxW3Tp7D5uKd/Pa4LH49sidJCZq5jlUqBxGpkZLSCL9+9ls+mLeGQV1acteZAzmwfVrYsaSGVA4iUiNJCXG0bZ7MzSf14cIR3YjXqS8ahL1u85nZRDNba2azK4zdamY/mtnM4DKmwn03mlmemS0wsxMrjI8KxvLMbEKF8W5m9o2ZLTKzF80sqTY/QRGpfSs3buf8x79h/upNAPz19AFcckR3FUMDsi8Tgk8Ao6oYv9fdDwoubwOYWV/gbKBf8JgHzSzezOKBB4DRQF/gnGBZgDuD58oCNgAX1+QTEpG6l5IYT/6G7fywflvYUaSO7LUc3P0zoHAfn+804AV33+HuS4E8YGhwyXP3Je5eArwAnGblJ1M5BnglePyTwNj9/BxEpB4sWL2ZG1/NpbQsQuumSUy59khO7Nc+7FhSR2pyKMFVZpYbTDvtOlatE7CiwjL5wdjuxtsAG9299CfjVTKz8WaWY2Y5BQUFNYguIvuqpDTCvVMWcvI/Pue9OWtYtn4rAAnxOhKpIavuV/choAdwELAKuDsYr2rC0asxXiV3f9Tds909OyMjY/8Si8h+m7liIyf/43Pu+3ARJw3owAe/O4qebXUkUmNQraOV3H3Nrutm9k/gzeBmPtClwqKdgZXB9arG1wEtzSwh2HqouLyIhGR7SRl3v7+AiV8upV3zFCb+KptjercLO5bUo2qVg5l1cPdVwc3TgV1HMk0GnjOze4COQBYwjfIthCwz6wb8SPlO63Pd3c3sY+BnlO+HGAe8Ud1PRkRqbmreOia8Oovlhds4b1gmE0b3Ji1F50NqbPZaDmb2PDASSDezfOAWYKSZHUT5FNAy4DIAd59jZi8Bc4FS4Ep3Lwue5yrgPSAemOjuc4KXuAF4wcxuB74DHq+1z05E9svXS9Zz7mPf0LVNKi+MH87w7m3CjiQhMffdTvFHtezsbM/JyQk7hkiDsLqomPYtUohEnGenLeesIZ1JSYwPO5bUATOb4e7Ze1tOhxuINHIPfpLH8fd+yppNxcTFGecPP0DFIDp9hkhj5O4U74zQJCmeMf07UFbmtErVyQnk/6gcRBqZlRu3c/Prs4mPMx49fwhd05ty9bFZYceSKKNyEGkkIhHnuWnLueOd+ZRFnP868UDcwXQ6JKmCykGkEVi6bis3TMpl2tJCRvRsw99OH0hmm9SwY0kUUzmINGClZREe+2Ip905ZSFJCHHedOZCzsjtj2lyQvVA5iDRQc1du4oZJucz6sYgT+rbjz2P70655StixJEaoHEQaqHdmr2JV0XYeOHcwYwa019aC7BeVg0gDMuOHDZSWRRjWvQ1XHdOTi0Z0o1VTHaIq+09vghNpICIR58ZXc7n7/YUAJCfEqxik2rTlIBLjpi5ex8DOLWmWnMDDvxxCW+1XkFqgLQeRGFW0fSfXv/I95/7zGx77fAkA3TOa0SxZf/NJzem7SCQGvTdnNX98fTbrt5ZwxcgeXH5Uj7AjSQOjchCJIQWbd3Dr5Dm8NWsVfTs0Z+KvDqF/pxZhx5IGSOUgEgPcnVe//ZHb3pzL9pIyfn/igYw/sjuJ+j/OUkdUDiJRrqQ0wqVP5fDpwgKGHNCKO88cSM+2zcKOJQ2cykEkyiUlxHFAm1T+dGo/zh9+AHFxejOb1D1tk4pEofwN2zjn0a+Zs7IIgNtO68+4w7qqGKTeqBxEolDTpATWbi5m1cbisKNII6VyEIkSc1YW8fuXv6e0LEKrpkm8f+1RHNe3XdixpJHSPgeRkBXvLOMfHy3i4U+X0Co1iR8Kt9EjoxnxmkKSEKkcREKUs6yQ6yflsqRgK2cN6cxNJ/Whpf6Xs0QBlYNICLbsKOW/353PU1//QMcWTXjqoqEc2Ssj7Fgi/6FyEKlnny4s4A+vzmJl0XbGHdqV3594IE11PiSJMvqOFKlHXy1ez7iJ0+iR0ZRXLj+UIQe0DjuSSJVUDiL1IH/DNjq3SmV499bcccYAxh7ciZTE+LBjieyWDmUVqWP/+9EiRv/P56wuKsbMOHtopopBop62HETqgLuzraSMpskJnDqoEwnxcaQ301FIEju05SBSy1YUbuOCidO45vnvcHcy26Ry+VE9SNAZVCWGaMtBpJZEIs5TXy3jrvcWYMCE0b3DjiRSbSoHkVqQt3YzN0yaxYwfNnBUrwz+esYAOrVsEnYskWpTOYjUwM6yCI98upj7P8wjNTmee34+iNMP7oSZTn0hsU3lIFJNs38s4vev5DJv1SZOGtiBW0/pR0ZactixRGqFykGkmqbMXcP6LTt45PwhnNivfdhxRGqVykFkP0xbWkhpJMJhPdK58uieXDSiGy1SE8OOJVLrVA4i+ygScf74+mxapiZyWI90khLiSErQ4anSMO31O9vMJprZWjObXWGstZlNMbNFwcdWwbiZ2f1mlmdmuWY2uMJjxgXLLzKzcRXGh5jZrOAx95v25EmU+WxhAZuLdxIXZzxy/hD+deEhYUcSqXP78mfPE8Con4xNAD509yzgw+A2wGggK7iMBx6C8jIBbgGGAUOBW3YVSrDM+AqP++lriYRiw9YSfvfiTC6YOI3Hv1gKQNf0pqQmaYNbGr69loO7fwYU/mT4NODJ4PqTwNgK4095ua+BlmbWATgRmOLuhe6+AZgCjArua+7uX7m7A09VeC6RULg7b+au5Lh7PmXy9yu55pieXDGyR9ixROpVdf8EaufuqwDcfZWZtQ3GOwErKiyXH4ztaTy/ivEqmdl4yrcyyMzMrGZ0kd1bs6mYm1+fzZS5axjYuQXPXDKMPh2ahx1LpN7V9vZxVfsLvBrjVXL3R4FHAbKzs3e7nMj+cndeylnB7W/No6Q0wh/G9OaiEd10PiRptKpbDmvMrEOw1dABWBuM5wNdKizXGVgZjI/8yfgnwXjnKpYXqTclpREufGIaX+atZ1i31tx55kC6pjcNO5ZIqKr7Z9FkYNcRR+OANyqMXxActTQcKAqmn94DTjCzVsGO6BOA94L7NpvZ8OAopQsqPJdInSrfzQVJCXH0apfGX07vz/OXDlcxiLAPWw5m9jzlf/Wnm1k+5Ucd3QG8ZGYXA8uBs4LF3wbGAHnANuBCAHcvNLM/A9OD5W5z9107ua+g/IioJsA7wUWkTq0o3MbvXprJLaf0o3+nFtxySr+wI4lElb2Wg7ufs5u7jq1iWQeu3M3zTAQmVjGeA/TfWw6R2tQ8JZFN20sp2LIj7CgiUUl726TR+H7FRq59cSalZRFapCbyzm+O4OgD2+79gSKNkN7NIw3e9pIy7v1gIY99voSMtGSWF26je0Yz4uL0ZnyR3VE5SIP21eL13PhqLsvWb+OcoZncOKY3zVN0ojyRvVE5SIO0qXgnd7wzn+e+Wc4BbVJ57tJhHNYjPexYIjFD5SANzofz1nDTa7NZu7mY8Ud259rjetEkKT7sWCIxReUgDcrUxeu4+MkcDmyXxsPnD+GgLi3DjiQSk1QOEvPcneWF2zigTVMO7d6Gv581iFMHddT/WhCpAf30SMy7/8M8Trr/C1YXFWNm/GxIZxWDSA1py0FikruztaSMZskJnDG4E02T48lISw47lkiDoT+vJOYsW7eVc//5DVc/9y3uTpfWqVxyRHfi9b4FkVqjLQeJGWURZ+IXS7l7ygIS4+L4w0l9wo4k0mCpHCQmLFi9metf+Z7v84s4rk9bbh87gPYtUsKOJdJgqRwkqu0oLePBjxfz4Cd5NE9J5B/nHMzJAztQfoZ3EakrKgeJWt8t38ANk3JZuGYLpx/ciT+e3JfWTZPCjiXSKKgcJGp9tnAdm4tLmfirbI7p3S7sOCKNispBosrUvHVEHA7PSueKkT246PCupOlEeSL1TuUgUaMs4tz25lxapSZxeFY6SQlxejObSEhUDhK6j+avIbtra5qnJPLo+dm0ba43s4mETX+WSWjWbdnBVc99y0VP5PCvL5YBkNkmlZREnUFVJGzacpB65+68PvNH/vTvuWzbUcZ1x/fi8pE9wo4lIhWoHKRerdy4nZtem8XHCwo4OLMld505kKx2aWHHEpGfUDlIvYhEnGenLefOd+ZTFnFuOaUvFxzaVedDEolSKgepcztKy7jg8Wl8s7SQw3um87czBtCldWrYsURkD1QOUmfcHTMjOSGeAZ1acOaQzpw1pLNOfSESA3S0ktSJ5eu3cfqDU5mVXwTAzSf35efZXVQMIjFC5SB1okVqIjvLImzYVhJ2FBGpBpWD1JoZP2zgque+ZWdZhBZNEnnz6sM5sldG2LFEpBq0z0FqbOuOUv7+/gKemLqMDs1TyN+wnW7pTTWFJBLDVA5SI58vKuDGV2eRv2E7Fxx6ANeP6k2zZH1bicQ6/RRLtRRt28ntb83l5Rn5dE9vykuXHcrQbq3DjiUitUTlIPvt3dmr+OMbcyjcWsKvR/bgmmOzdD4kkQZG5SD7ZWreOi5/5lv6dmjOv351CP07tQg7kojUAZWD7JW7s3TdVrpnNOPQHm247+yDGDOgA4nxOthNpKHST7fs1b0fLOKUf3zB6qJizIzTDuqkYhBp4LTlIFWKRJwtJaU0T0nkrCGdSW+WRNs0/RMekcaiRn/+mdkyM5tlZjPNLCcYa21mU8xsUfCxVTBuZna/meWZWa6ZDa7wPOOC5ReZ2biafUpSU4sLtvCLR7/i6ue+w93p0jqVCw7tSpzOoCrSaNTG3MDR7n6Qu2cHtycAH7p7FvBhcBtgNJAVXMYDD0F5mQC3AMOAocAtuwpF6tfOsggPfpLH6Ps+Z+GaLZwyqGPYkUQkJHUxrXQaMDK4/iTwCXBDMP6UuzvwtZm1NLMOwbJT3L0QwMymAKOA5+sgm+zG7B+LuGFSLnNWbmLMgPbcemo/2qalhB1LREJS03Jw4H0zc+ARd38UaOfuqwDcfZWZtQ2W7QSsqPDY/GBsd+NSD4p3lnH/h4t45LMltEpN4uFfDmZU/w5hxxKRkNW0HEa4+8qgAKaY2fw9LFvVhLXvYbzyE5iNp3xKiszMzP3NKj+Rs6yQ6yflsqRgK2cN6czNJ/WlRWpi2LFEJArUaJ+Du68MPq4FXqN8n8GaYLqI4OPaYPF8oEuFh3cGVu5hvKrXe9Tds909OyNDZ/usqa8Wr6ekNMLTFw/lv88apGIQkf+odjmYWVMzS9t1HTgBmA1MBnYdcTQOeCO4Phm4IDhqaThQFEw/vQecYGatgh3RJwRjUgc+XVjAZwsLALh8ZA/e++2RHJGlohWR/19NppXaAa8Fp2VOAJ5z93fNbDrwkpldDCwHzgqWfxsYA+QB24ALAdy90Mz+DEwPlrtt185pqV1lEedvb8+jTbMkjuyVQWJ8nN7MJiJVsvKDh2JPdna25+TkhB0jJrw7ezWH9WxD85RE8jdsI71Zsk6UJ9JImdmMCm892C392diArd1UzOVPz+DyZ2bwxJfLAOjcKlXFICJ7pdNnNEDuzssz8rn9zbnsKI0wYXRvLjm8W9ixRCSGqBwamBWF27jx1Vl8kbeOoV1bc8eZA+ie0SzsWCISY1QODURZxHnqq2Xc9e4C4gz+PLY/5w3N1PmQRKRaVA4NwI7SMs795zfM+GEDIw/M4C+nD6BTyyZhxxKRGKZyiGHujpmRnBDPIV1b88vhmYw9qBPB4cUiItWmo5Vi1LJ1Wznlf78gN38jABNG9+b0gzurGESkVqgcYlTrZknEm7G5uDTsKCLSAKkcYsg3S9Zz+dMzKCmN0DwlkdevHMGInulhxxKRBkj7HGLA5uKd3PnufJ75ejldWjdh5cbtdE1vqikkEakzKoco9/H8tfzhtVms3lTMRSO68V8n9iI1SV82Ealb+i0TpQq3lnDbv+fw+syVZLVtxqQrDmNwpv57qojUD5VDlHF33sxdxa2T51C0fSfXHNOTK4/pSXKCzockIvVH5RBlpi5ez9XPf8eATi145pJh9OnQPOxIItIIqRyigLuTt3YLWe3SOKxHG/5xzsGM7t+eBP2vBREJiX77RIF7pizktAe+ZHVRMWbGKYM6qhhEJFTacghJWcTZUlxKi9REzh6aSYcWTWiblhx2LBERQFsOoVi4ZjNnPjSVq57/FnenU8smnDtMZ1AVkeihcqhHJaUR7vtgESfd/znLC7fxsyGdw44kIlIlTSvVk+9XbOSGSbnMX72ZUwd15JZT+tKmmaaRRCQ6qRzq2PaSMu79YCGPfb6EtmkpPHZBNsf1bRd2LBGRPVI51KGvl6xnwqRclq3fxjlDM7lxTG+apySGHUtEZK9UDnVoxg8bcOC5S4dxWA+dPVVEYofKoZZ9MHcN8fHG0Qe2ZfyR3bloRDeaJOnUFyISW1QOtags4tw9ZSHpzZI4+sC2JMbHkaheEJEYpHKoIXfnrVmrOCIrgxZNEnl8XDbpOgpJRGKc3udQA6uKtnPJkzlc9dx3PP3VMgA6tmxCUoJWq4jENm05VEMk4jw/fTl/e3s+pZEIN5/UhwtHdAs7lohIrVE57Kdl67Yy4dVcvl5SyGE92nDHGQPJbJMadiwRkVqlcthHpWURJn65lLvfX0hSfBx3nDGAXxzSRf/HWUQaJJXDPthRWsbPH/ma71ds5Lg+7bh9bH/at0gJO5aISJ1ROexBJOLExRnJCfGM6NGGSw7vxskDO2hrQUQaPB1WsxtLCrYw5v7P+W75BgCuH9WbUwZ1VDGISKOgctiNjLRkUpPiKd4ZCTuKiEi9UzlUMDVvHZc8mUNJaYS0lEQmXXEYh/ZoE3YsEZF6p30OQNH2nfzt7Xm8MH0F3dKbsqpoOwe0aaopJBFptKKmHMxsFHAfEA885u531Mfrvj9nNTe/Ppt1W3Zw2VHdufa4XqTohEgi0shFRTmYWTzwAHA8kA9MN7PJ7j63rl5z3ZYd3Dp5Dm/mrqJ3+zQeG5fNwM4t6+rlRERiSlSUAzAUyHP3JQBm9gJwGlDr5eDuvD7zR/7077ls21HGdcf34vKRPUiM1+4XEZFdoqUcOgErKtzOB4bVxQt9mbeea1/8noMzW3LXmQPJapdWFy8jIhLToqUcqtrz65UWMhsPjAfIzMys1guN6NmGh385mOP7tic+TjucRUSqEi1zKflAlwq3OwMrf7qQuz/q7tnunp2RkVGtFzIzRvXvoGIQEdmDaCmH6UCWmXUzsyTgbGByyJlERBqtqJhWcvdSM7sKeI/yQ1knuvuckGOJiDRaUVEOAO7+NvB22DlERCR6ppVERCSKqBxERKQSlYOIiFSichARkUpUDiIiUom5V3ojckwwswLgh2o+PB1YV4tx6lMsZwflD1MsZ4fYzh9N2Q9w972+izhmy6EmzCzH3bPDzlEdsZwdlD9MsZwdYjt/LGbXtJKIiFSichARkUoaazk8GnaAGojl7KD8YYrl7BDb+WMue6Pc5yAiInvWWLccRERkDxpVOZjZKDNbYGZ5ZjYh7Dx7Y2ZdzOxjM5tnZnPM7DfBeGszm2Jmi4KPrcLOujtmFm9m35nZm8Htbmb2TZD9xeAU7VHJzFqa2StmNj/4GhwaY+v+2uD7ZraZPW9mKdG6/s1sopmtNbPZFcaqXNdW7v7g5zjXzAaHl/w/WavK/9/B906umb1mZi0r3HdjkH+BmZ0YTuo9azTlYGbxwAPAaKAvcI6Z9Q031V6VAte5ex9gOHBlkHkC8KG7ZwEfBrej1W+AeRVu3wncG2TfAFwcSqp9cx/wrrv3BgZR/nnExLo3s07ANUC2u/en/FT4ZxO96/8JYNRPxna3rkcDWcFlPPBQPWXckyeonH8K0N/dBwILgRsBgp/hs4F+wWMeDH4/RZVGUw7AUCDP3Ze4ewnwAnBayJmwrVpgAAAC+klEQVT2yN1Xufu3wfXNlP9y6kR57ieDxZ4ExoaTcM/MrDNwEvBYcNuAY4BXgkWiOXtz4EjgcQB3L3H3jcTIug8kAE3MLAFIBVYRpevf3T8DCn8yvLt1fRrwlJf7GmhpZh3qJ2nVqsrv7u+7e2lw82vK/8MllOd/wd13uPtSII/y309RpTGVQydgRYXb+cFYTDCzrsDBwDdAO3dfBeUFArQNL9ke/Q9wPRAJbrcBNlb4gYnmr0F3oAD4VzAt9piZNSVG1r27/wj8HVhOeSkUATOInfUPu1/XsfizfBHwTnA9JvI3pnKo6p9Gx8ShWmbWDJgE/NbdN4WdZ1+Y2cnAWnefUXG4ikWj9WuQAAwGHnL3g4GtROkUUlWC+fnTgG5AR6Ap5dMxPxWt639PYun7CDO7ifIp4md3DVWxWNTlb0zlkA90qXC7M7AypCz7zMwSKS+GZ9391WB4za7N6ODj2rDy7cEI4FQzW0b5FN4xlG9JtAymOSC6vwb5QL67fxPcfoXysoiFdQ9wHLDU3QvcfSfwKnAYsbP+YffrOmZ+ls1sHHAycJ7/3/sGYiJ/YyqH6UBWcLRGEuU7hCaHnGmPgjn6x4F57n5PhbsmA+OC6+OAN+o72964+43u3tndu1K+rj9y9/OAj4GfBYtFZXYAd18NrDCzA4OhY4G5xMC6DywHhptZavB9tCt/TKz/wO7W9WTgguCopeFA0a7pp2hiZqOAG4BT3X1bhbsmA2ebWbKZdaN8x/q0MDLukbs3mgswhvKjBhYDN4WdZx/yHk755mYuMDO4jKF87v5DYFHwsXXYWffyeYwE3gyud6f8ByEPeBlIDjvfHnIfBOQE6/91oFUsrXvgT8B8YDbwNJAcresfeJ7yfSM7Kf/L+uLdrWvKp2UeCH6OZ1F+RFY05s+jfN/Crp/dhyssf1OQfwEwOuz8VV30DmkREamkMU0riYjIPlI5iIhIJSoHERGpROUgIiKVqBxERKQSlYOIiFSichARkUpUDiIiUsn/A/sYnaVq2ifNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4a02b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(f_arr, '-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c475128>]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHmNJREFUeJzt3Xl4VOXB/vHvk50kEBISIISEBNmXQDBs0lqlLiiCLNal7tri27f+ql1EtFi1al3qa9UuKtSl2qqVTRBRcRdFKAQhC/sqIUDCEiCErPP8/sjQIkUyhEzOnJn7c125kjk5JveZE2+eOefMc4y1FhERcY8wpwOIiMipUXGLiLiMiltExGVU3CIiLqPiFhFxGRW3iIjLqLhFRFxGxS0i4jIqbhERl4nwxw9NTk62mZmZ/vjRIiJBKS8vb4+1NsWXdf1S3JmZmSxfvtwfP1pEJCgZY7b5uq4OlYiIuIyKW0TEZVTcIiIuo+IWEXEZn05OGmO2AoeAeqDOWpvrz1AiIvLtTuWqknOttXv8lkRERHyiQyUiIi7ja3FbYKExJs8YM8mfgURE3GjD7kMt9rt8Le4R1tpBwEXAT40xZx+/gjFmkjFmuTFmeVlZWbOGFBEJZJU1dVwxbQkLi3a1yO/zqbittSXez6XAHGDICdaZZq3NtdbmpqT49K5NERFXW7Z1Hx6PJTYqguevz2VEt+QW+b2NFrcxJs4Y0/ro18AFQKG/g4mIBKr9h2v4xRsr+cGzXzJzRTEAORmJxEX7ZRaR/+LLb+kAzDHGHF3/VWvtu35NJSISgKy1vFO4i9/MLaS8spafjezGpQM7tXiORovbWrsZGNACWUREAlbpwSrumVvIe0W76Z+WwMs3DaVPpzaOZGmZcb2IiEtZa5mRV8yD81dTXefhrot6cfN3sogId+5qahW3iMi3OFBZy09fXcHnG/cwJCuJRyb0p2tKvNOxVNwiIt8mPiaC8DDDg+P68cMhGYSFGacjAXrnpIjIN2wuq+Cml5axp6Ka8DDDSzcO5pphXQKmtEHFLSLyDfUeS1HJATaVVgDgvaIuoKi4RSTk5ReX8/v31gLQvUNrFk0eydCu7RxO9e1U3CISsqpq63l4wRrG/fkLZuYVs6eiGoCoiMCuRp2cFJGQtGTzXqbMymfr3kquGpLOXRf3pk1MpNOxfKLiFpGQcqiqlkfeWcs/ln5NRlIsr/5oKGe10BwjzUXFLSIh4+O1pdw9p4DdB6v40Xey+OUFPWkVFe50rFOm4haRkDB35Q5ue30lPTrE85erzyInI9HpSE2m4haRoGWtZd/hGtrFR3NBn45MHd2b64ZnBvzJx8a4O72IyEnc/9ZqJjyzmCM19bSKCudH3+3q+tIGjbhFJMhYa6mtt0RFhDGqX0fS2rYiMjzw3kRzOtz/T4+IiNe2vYf54fSlPL5wHQDDurbjx2d3dXQmP3/QiFtEXK/eY3nxiy08vnAdkWFhjMtp+ZsbtCQVt4i42rpdh5g8K59V28s5r3d7HhzXn44JMU7H8isVt4i4Uk2dh798spE/f7yR1jGRPH1VDmOyUwNyUqjmpuIWEddZub2cO2fms273IcYN7MRvxvQlKS7K6VgtRsUtIq7zwudbOFhVyws35DKyVwen47Q4FbeIuMLiTXto3zqabu1bc//YvkSEG1q7ZFKo5hZc18iISFCqrKnj1le/4ukPNwKQGBcVsqUNGnGLSABbvGkPQ7PaERsVwUs3DqZ7+9ZORwoIGnGLSMDZW1HN/3vtK344fSmzVhQDkN25rStn8vMHjbhFJGBYa5m3qoT75hVRUV3HL87vwbiBaU7HCjgqbhEJCCXlR5j6ZiEfrS1lYHpbHrssmx4ddGjkRFTcIuIoj8fy2rKveXjBWuo9lnsu6cMNZ2USHhb8b6RpKhW3iDimvLKGW17JY+mWfYzo1o6Hx2eT0S7W6VgBT8UtIo5pExNJfHQEj07sz+W56SHxdvXmoKtKRKRFbSw9xLXPL6X0UBVhYYbnbxjMFYMzVNqnQMUtIi3KGMOm0gq27a10Oopr+VzcxphwY8xXxpj5/gwkIsEnb9t+Hn5nDQBnpMTz6eRzGZyZ5HAq9zqVEfdtwBp/BRGR4FNZU8f9bxVx2bOLeWtlCXsrqgGIDLI70rQ0n05OGmM6A6OBh4Bf+DWRiASFzzfsYcrsfIr3H+G64V2YPKoX8dG6HqI5+PosPglMBnQ1vIic1IEjtTz09mreWF5MVnIcb9wynCFZOizSnBotbmPMJUCptTbPGHPOSdabBEwCyMjIaLaAIuIe7xXt4p43C9l7uIafnHMGt32/OzGRml+kufky4h4BjDXGXAzEAG2MMX+31l5z7ErW2mnANIDc3Fzb7ElFJKC9+dUObv/nSnqntuH56wfTv3OC05GCVqPFba29C7gLwDvi/tXxpS0ioclaS1lFNe1bxzCqX0fuq+zD1cO66OSjn+nZFZEmu3deEROfWUxlTR0xkeHcMCJLpd0CTukUr7X2E+ATvyQREVfweCy1Hg/REeFckt2JrOQ4oiN0HLsl6Z9GEfHZprIKrpj2JY+9uw6AIVlJ3DgiSzP5tTBdVCkijaqt9zB90Wae/GADMRFhXJ6b7nSkkKbiFpGTKtxxgDtn5VNUcpBRfTvy20v70r5NjNOxQpqKW0ROqKq2nj9+tIFnP91MYmwUz1w9iIv6pzodS1Bxi8gJLN+6j8mz8tlcdpjLzuzM1NG9aRsb5XQs8VJxi8h/eWXJNqprPbx80xDO7pHidBw5jopbRAD4bH0ZqQkxdO/Qmt+O7UdEuCFOk0IFJF0OKCIcrq7j9n+u5M8fbwQgITZSpR3AtGdEQtiiDWWcdUYycdERvHLzEM5IiXc6kvhAI26REFR6qIqf/D2Pa5//F7NXFAPQt1OCZvJzCY24RUKItZaZecU8+PYajtTWM3lUT8blpDkdS06RilskRGzfV8ndcwpYtGEPgzMTeWRitg6NuJSKWyTIeTyWl7/cymPvrcMAD1zal6uHdiFM84u4lopbJIiVV9Zw89+Wk7dtP9/rkcJD4/vROTHW6VhymlTcIkGsTUwkyfFRPHH5AMbnpGGMRtnBQFeViASZ9bsPcdW0JZQerCIszPDctblMGNRZpR1EVNwiQSYizFBcXsn2/ZVORxE/UXGLBIFlW/fx0NurAeiaEs/HvzyHM7skOZxK/EXFLeJiFdV1/GZuIT949kveKdzF3opqACJ038egppOTIi718bpSfj27gJ0Hq7hpRBa/urAHsVH6XzoUaC+LuMz+wzU8MH81s7/aQbf28cz8n7M4s0ui07GkBam4RVzCWsuCgl3cO6+Q8spafjayGz8d2U13WA9BKm4Rl5jz1Q5+8cYq+qcl8MrNQ+md2sbpSOIQFbdIALPWsvtgNR0TYri4fyqVNfVcOThdJx9DnPa+SAD79ZuFXPbsYipr6oiJDOeaYV1U2qIRt0igqfdYaus9xESGMyEnjT6pbYjRcWw5hv7pFgkgG3Yf4rJnF/Pou2sByM1M4pphmslPvknFLRIAauo8PP3hBkY//Tlb9xxmYHpbpyNJANOhEhGHrdpezp2z8lm76xBjBnTi3jF9SI6PdjqWBDAVt4hDjtTU8+QH65m+aDMpraOZfl0u5/fp4HQscQEVt4gDvty0l7tm57N1byVXDUlnykW9SWgV6XQscYlGi9sYEwN8BkR7159prb3X38FEgtkby7fjsfDqj4ZyVrdkp+OIy/gy4q4GRlprK4wxkcDnxph3rLVL/JxNJKh8tHY3aW1j6dmxNfeN7UtkuNGkUNIkjV5VYhtUeB9Gej+sX1OJBJnD1XXcMSOf5z7dBEBCq0iVtjSZT5cDGmPCjTErgVLgfWvt0hOsM8kYs9wYs7ysrKy5c4q4jrWWj9eWUu+xxEVH8I8fD+WRidlOx5Ig4FNxW2vrrbUDgc7AEGNMvxOsM81am2utzU1JSWnunCKusutAFT9+OY8bX1rGnK92ANCrYxuiIvTWCTl9p/RazVpbboz5BBgFFPolkYiLWWt5fdl2fvf2Gmo9HqaO7s34nDSnY0mQ8eWqkhSg1lvarYDzgEf9nkzEZbbtPcyUWQV8uXkvw7u245GJ/enSLs7pWBKEfBlxpwJ/M8aE03Bo5Q1r7Xz/xhJxj3qP5cUvtvD4wnVEhoXx8IT+XDk4HWM0v4j4R6PFba3NB3JaIIuI6+w/XMMNLy1j1fZyzuvdngfH9adjQozTsSTI6XokkdOQ0CqSzm1bcfN3shiTnapRtrQIneIWOUVrdh7kB88uZteBKsLCDH++ehBjB3RSaUuLUXGLnKKYyHD2VNRQcuCI01EkRKm4RXyweNMe7ptXhLWWrOQ4PvjF9xiUkeh0LAlRKm6RkzhYVctds/P54fSlfLKulP2VtQCE64404iCdnBT5Fu+v3s3UNwsoO1TNLWd35fbzetAqSvd+FOepuEWOs6eimvvmFTE/fye9OrZm+nW5ZHfWrcQkcKi4RbystcxdWcL9bxVxuLqeX57fg1u+d4bmF5GAo+IW8Zq1Yge/mrGKnIy2PDYxm+4dWjsdSeSEVNwS0jwey86DVaS1bcUl2anUezxcdma6Tj5KQNNrQAlpd88p4PJnv6Sypo6YyHCuGJyh0paApxG3hJy6eg91HktMZDg/yE1nUEYirSJ1tYi4h0bcElLW7DzIhGcW88g7awE4s0sil2smP3EZFbeEhOq6ep5YuI4xf/ycHfuPkJupdz2Ke+lQiQS9vG37uXNWPhtLK5iQk8Y9l/QhMS7K6VgiTabilqBVWVPH799bx0uLt5LaJoYXbxzMuT3bOx1L5LSpuCUofb5hD1Nm51O8/wjXDe/C5FG9iI/Wn7sEB/0lS1Ca89UOosLDeOOW4QzJSnI6jkizUnFL0HivaBcZSbH0Tm3DfWP7EBkeRowu85MgpKtKJChUVNfx6zkF/HXRFgBax0SqtCVoacQtrmWtZeHq3Xy/V3vioyN47cfDyEyOczqWiN9pxC2utKP8CDe8uIxbXsnjzZUlAHTv0JrIcP1JS/DTiFtcxeOx/H3pNh59Zy0WuG9MHybkpDkdS6RFqbjFNTaVVTBlVj7Ltu7nu92T+d34/qQnxTodS6TFqbgl4NXWe5i+aDNPfrCBVpHhPP6DAUwclKb5RSRkqbgloO07XMO1zy+lqOQgF/XryP2X9qV96xinY4k4SsUtAclaizGGxNhIurWP59Zzu3FR/1SnY4kEBJ2Cl4BTVHKA8X9ZzM4DRzDG8NSVOSptkWOouCXgxEdHUFFdR+nBaqejiAQkFbcEhE/XlzH1zQKstXRpF8fC289mQHpbp2OJBKRGj3EbY9KBl4GOgAeYZq19yt/BJDSUV9bwwPw1zFpRzBkpcZRX1pIYF0WY7vso8q18OTlZB/zSWrvCGNMayDPGvG+tXe3nbBLk3inYyT1zi9hfWcOt53bj1pHdNL+IiA8aLW5r7U5gp/frQ8aYNUAaoOKWJik9WMVv5hbxbtEu+qW14W83DaZvpwSnY4m4xildDmiMyQRygKX+CCPBzVrLjLxiHpy/mqo6D3eO6sWPv5tFhOYXETklPhe3MSYemAXcbq09eILvTwImAWRkZDRbQAkeM/KKmTwznyGZSTwysT9dU+KdjiTiSj4VtzEmkobS/oe1dvaJ1rHWTgOmAeTm5tpmSyiuVu+xlJQfIT0plksHdiLcGMbnpOnko8hpaPQ1qmmYEOJ5YI219gn/R5JgMmVWPlc89yWVNXVER4Qz8czOKm2R0+TLiHsEcC1QYIxZ6V12t7V2gf9iiZvV1nuoq7e0igrnh0MzGH5GO1rpahGRZuPLVSWfAxoiiU8Kdxzgjpn55HZJ5IFx/cjJSCQnI9HpWCJBRZNMSbOoqq3nyQ82MH3RZpLiovhO92SnI4kELRW3nLZ/bdnHlFn5bN5zmCty07n74t4kxEY6HUskaKm4pckOVdXy2LvreGXJNtKTWvH3m4dqpC3SAlTc0iQfryvl17ML2HmwiptGZPGrC3sQG6U/J5GWoP/TpEkW5O8kLjqCWT85i0E6+SjSolTc4hNrLW8X7CQrOY6+nRK4d2xfIsMN0RG6zE+kpWmSCPHJ4Zp67pu3mpe+2Ao03OxApS3iDI245VtZa1lQsIsL+3YgPjqCf94yjC5JsU7HEgl5GnHLCX29t5Jrnl/KT19dwdyVJQCckRKvmfxEAoBG3PIN9R7LS4u38vh76wgPMzw0vh/jc9KcjiUix1Bxy7+t332IyTPzWbm9nJG92vPQ+H6kJrRyOpaIHEfFLdTUeXjmk0386eMNxEdH8NSVAxk7oBMNE0OKSKBRcYe4vRXVXP3XpazddYixAzpx75g+tIuPdjqWiJyEijtEWWsxxpAUF0WfTm341QU9Oa9PB6djiYgPdIlACCooPsCYP31OSfkRjDE8cflAlbaIi6i4Q1Db2Ejq6i17K2qcjiIiTaDiDhEfrd3NXbPzsdaSnhTLO7d9l/6dE5yOJSJNoGPcQW5vRTW/nb+auStL6NEhnvLKWhLjonTFiIiLqbiDlLWWeatKuP+t1RyqquX287rzv+d0IypCL7JE3E7FHYR2HjjC1DmFfLi2lAHpbXlsYjY9O7Z2OpaINBMVdxDxeCyvL9vOwwvWUOvxMHV0b24ckUV4mA6LiAQTFXcQmZlXzN1zCjjrjHY8PKE/XdrFOR1JRPxAxe1y9R7L9n2VZCbHMS4njZiocMZkp+rko0gQ05kql7tj5iqunLaEypo6oiLCNMeISAjQiNuFauo81Hk8xEZFcP3wTM7t2Z5WkbobjUio0IjbZVZuL+eSPy7iobfXADAgvS1jNMoWCSkacbtEZU0dTyxczwtfbKFDmxi+37u905FExCEqbhdYvHEPU2YX8PW+Sq4ZlsGdo3rROibS6Vgi4hAVdwA7cKSWhxes4fVl28lsF8vrk4YxrGs7p2OJiMNU3AHq/dW7mfpmAWWHqrnle135+Xk9iNEJSBFBxR2wPli9m8TYKKZfl0t257ZOxxGRANJocRtjXgAuAUqttf38Hyk0WWuZu7KEbu3j6ZeWwG/G9CEyPEyTQonIf/GlFV4CRvk5R8g7XFPP7xas4ZUvtwEQFx2h0haRE2p0xG2t/cwYk+n/KKHH47G8lV/Cxf1TiY+O4I1bhpOeFOt0LBEJcM12jNsYMwmYBJCRkdFcPzZobdlzmDtn5fOvLfuo91gmDOpMZrImhRKRxjVbcVtrpwHTAHJzc21z/dxgU1fv4a+fb+EP768nOiKMxy7LZnxOmtOxRMRFdFVJC1pdcpDJs1ZRuOMgF/btwAOX9qN9mxinY4mIy6i4W0B1XT1/+mgjz3yyibaxkfzl6kFc1K+j5hcRkSbx5XLA14BzgGRjTDFwr7X2eX8HCxZ7Kqq5ctoSNpZWMHFQZ6aO7k1iXJTTsUTExXy5quSqlggSbKy1GGNoFxfFmRmJTB3dm3N6amIoETl9ulDYD1ZuL+eipxaxo/wIxhgevSxbpS0izUbF7Qft4qKIDA+jvLLG6SgiEoRU3M3k3cJd3DFjFdZa0pNimXfrCPp2SnA6logEIV1VcppKD1Vx37wiFhTsok9qG8ora0mMi9IVIyLiNyruJrLWMmvFDh6Yv5ojNfXccWFPJp3dlchwvYgREf9ScTdB8f5K7p5TyGfryzizSyKPTsymW/t4p2OJSIhQcZ8Cj8fyypJtPPruWgDuG9OH64ZnEhamwyIi0nJU3KdgRt527p1XxHe7J/O78f01k5+IOELF3Yjaeg/b91XSNSWe8TmdiY+O5OL+eru6iDhHZ9IaMXlmPldNX0JlTR1REWGMzk5VaYuIozTiPoGq2nrqPZa46AhuGpHFhX07EBulp0pEAoNG3MdZvnUfFz+9iAffXg1A/84JjOqX6nAqEZH/0DDSq6K6jt+/u5aXl2yjU0IrLlJZi0iAUnEDn64v4+7ZBZQcOML1wzO548KexEXrqRGRwBTS7VReWcMD89cwa0UxZ6TEMeOW4eRmJjkdS0TkpEK2uN8p2Mk9c4vYX1nDred249aR3YiJDHc6lohIo0K2uD/bUEaHNtH87abBmsVPRFwlZIrbWsuMvGJ6dWxNdue23HNJH6LCw4jQpFAi4jIh01qHa+r5v4XreO1f2wGIjYpQaYuIKwX1iLveY5nz1Q4uHdiJ+OgIZv7PWaS1beV0LBGR0xK0xb2x9BCTZ+az4utyIsIM43LSNCmUiASFoCvu2noPz326iac/3EhsdDh/uGIAlw7s5HQsEZFmE1TFXVB8gDtmrmLtrkOMzk7l/rF9SY6PdjqWiEizCorirqqt58kPNjB90WbaxUXx3LVncmHfjk7HEhHxC9cXd9mhai5/7ku27DnMFbnp3D26NwmtIp2OJSLiN64tbo/HEhZmSI6PYljXdjw4rh8juiU7HUtExO9ceSHziq/3c8GTn7F9XyXGGB6e0F+lLSIhw5XF3b51NPHREVRU1zkdRUSkxbmiuK21zM8v4ef/XIm1ls6Jscz537PondrG6WgiIi0u4I9x7z5YxdQ3C3l/9W6yOydw4EgtbWOjdN9HEQlZPhW3MWYU8BQQDvzVWvuIX1PRMMp+Y/l2Hnx7DTV1Hu6+uBc3jcjS/CIiEvIaLW5jTDjwZ+B8oBhYZoyZZ61d7a9QX++tZMrsfBZv2svQrCQenZhNZnKcv36diIir+DLiHgJstNZuBjDGvA5cCjR7cdd7LC9+sYX/W7ie8DDDQ+P7cdXgDMLCdFhEROQoX4o7Ddh+zONiYKg/wszwHhoZ2as9D43vR2qCZvITETmeL8V9ouGu/a+VjJkETALIyMhoUpiJZ3YmKS6K8/t00MlHEZFv4cuZvmIg/ZjHnYGS41ey1k6z1uZaa3NTUlKaFCYyPIwL+nZUaYuInIQvxb0M6G6MyTLGRAFXAvP8G0tERL5No4dKrLV1xphbgfdouBzwBWttkd+TiYjICfl0Hbe1dgGwwM9ZRETEB3o3i4iIy6i4RURcRsUtIuIyKm4REZdRcYuIuIyx9r/eBHn6P9SYMmBbE//zZGBPM8ZxC213aAnF7Q7FbQbft7uLtdandy/6pbhPhzFmubU21+kcLU3bHVpCcbtDcZvBP9utQyUiIi6j4hYRcZlALO5pTgdwiLY7tITidofiNoMftjvgjnGLiMjJBeKIW0RETiJgitsYM8oYs84Ys9EYM8XpPM3JGJNujPnYGLPGGFNkjLnNuzzJGPO+MWaD93Oid7kxxjztfS7yjTGDnN2C02OMCTfGfGWMme99nGWMWerd7n96pwvGGBPtfbzR+/1MJ3OfDmNMW2PMTGPMWu9+Hx4K+9sY83Pv33ihMeY1Y0xMMO5vY8wLxphSY0zhMctOef8aY673rr/BGHO9r78/IIr7mBsSXwT0Aa4yxvRxNlWzqgN+aa3tDQwDfurdvinAh9ba7sCH3sfQ8Dx0935MAp5p+cjN6jZgzTGPHwX+4N3u/cDN3uU3A/uttd2AP3jXc6ungHettb2AATRsf1Dvb2NMGvAzINda24+GaaCvJDj390vAqOOWndL+NcYkAffScCvIIcC9R8u+UdZaxz+A4cB7xzy+C7jL6Vx+3N65wPnAOiDVuywVWOf9+jngqmPW//d6bvug4Y5JHwIjgfk03ApvDxBx/L6nYc734d6vI7zrGae3oQnb3AbYcnz2YN/f/Of+tEne/TcfuDBY9zeQCRQ2df8CVwHPHbP8G+ud7CMgRtyc+IbEaQ5l8Svvy8EcYCnQwVq7E8D7ub13tWB6Pp4EJgMe7+N2QLm1ts77+Nht+/d2e79/wLu+23QFyoAXvYeI/mqMiSPI97e1dgfwOPA1sJOG/ZdH8O/vo051/zZ5vwdKcft0Q2K3M8bEA7OA2621B0+26gmWue75MMZcApRaa/OOXXyCVa0P33OTCGAQ8Iy1Ngc4zH9eNp9IUGy392X+pUAW0AmIo+EwwfGCbX835tu2s8nbHyjF7dMNid3MGBNJQ2n/w1o727t4tzEm1fv9VKDUuzxYno8RwFhjzFbgdRoOlzwJtDXGHL370rHb9u/t9n4/AdjXkoGbSTFQbK1d6n08k4YiD/b9fR6wxVpbZq2tBWYDZxH8+/uoU92/Td7vgVLcQX1DYmOMAZ4H1lhrnzjmW/OAo2eSr6fh2PfR5dd5z0YPAw4cfQnmJtbau6y1na21mTTs04+stVcDHwOXeVc7fruPPh+Xedd33QjMWrsL2G6M6eld9H1gNUG+v2k4RDLMGBPr/Zs/ut1Bvb+Pcar79z3gAmNMovfVygXeZY1z+gD/MQfmLwbWA5uAXzudp5m37Ts0vATKB1Z6Py6m4Xjeh8AG7+ck7/qGhqtsNgEFNJyld3w7TvM5OAeY7/26K/AvYCMwA4j2Lo/xPt7o/X5Xp3OfxvYOBJZ79/mbQGIo7G/gfmAtUAi8AkQH4/4GXqPhOH4tDSPnm5uyf4GbvNu/EbjR19+vd06KiLhMoBwqERERH6m4RURcRsUtIuIyKm4REZdRcYuIuIyKW0TEZVTcIiIuo+IWEXGZ/w8RByjaVEqXIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11def0278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_arr, '-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x110839ef0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fe1f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_left_tensor = torch.from_numpy(sp_arr)\n",
    "sp_right_tensor = torch.from_numpy(sp_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tensor = torch.stack((sp_left_tensor, sp_right_tensor), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 129, 984])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 129, 984])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_tensor.unsqueeze_(0)\n",
    "sp_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to build a dataset to use as input for a network, we will stack multiple spectrograms representing multiple sounds in a dataset along the first dimension, leading to a B x C x F x T tensor.\n",
    "\n",
    "Such tensor is indistinguishable from what we would build for a dataset set of images, where F is represents rows and T columns of an image. Indeed, we would tackle a sound classification problem on spectrograms with the exact same networks. Time to tackle images now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.5  Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = imageio.imread('cats/cat3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, img is a NumPy array-like object with three dimensions: two spatial dimensions, width and height, and a third dimension correponding to channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch modules dealing with image data require tensors to be laid out as C x H x W, channels, height and width, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.from_numpy(img_arr)\n",
    "out = torch.transpose(img, 0, 2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "batch = torch.ByteTensor(batch_size, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat1.png', 'cat2.png', 'cat3.png']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'cats/'\n",
    "filenames = [name for name in os.listdir(data_dir) if name.endswith('.png')]\n",
    "\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(data_dir+filename)\n",
    "    img_arr = img_arr[...,:3]\n",
    "    batch[i] = torch.transpose(torch.from_numpy(img_arr), 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 4)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread(data_dir+filename)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr[...,:3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possibility is to just divide the values of pixels by 255 (the maximum representable number in 8-bit unsigned):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batch.float()\n",
    "batch /= 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is to compute mean and standard deviation of the input data and scale it so that the output has zero mean and unit standard deviation across each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.6  Volumetric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just have an extra dimension, depth, after the channel dimension, leading to a 5D tensor of shape B x C x D x H x W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import imageio\n",
    "\n",
    ">>> vol_arr = imageio.volread(dirname, 'DICOM')\n",
    ">>> vol_arr.shape\n",
    "\n",
    "(256, 256, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> vol = torch.from_numpy(col_arr).float()\n",
    ">>> vol = torch.transpose(vol, 0, 2)\n",
    ">>> vol = torch.unsqueeze(vol, 0)\n",
    "\n",
    ">>> vol.shape\n",
    "\n",
    "torch.Size([1, 1, 50, 256, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = imageio.get_reader('cockatoo.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = reader.get_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 14.0,\n",
       " 'ffmpeg_version': '3.2.4-tessus built with Apple LLVM version 8.0.0 (clang-800.0.42.1)',\n",
       " 'fps': 20.0,\n",
       " 'nframes': 280,\n",
       " 'plugin': 'ffmpeg',\n",
       " 'size': (1280, 720),\n",
       " 'source_size': (1280, 720)}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 3\n",
    "n_frames = meta['nframes']\n",
    "video = torch.FloatTensor(n_frames, n_channels, *meta['size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([280, 3, 1280, 720])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, frame in enumerate(reader):\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    video[i] = torch.transpose(frame, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([720, 1280, 3])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1280, 720])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(frame, 0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch04]",
   "language": "python",
   "name": "conda-env-pytorch04-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
